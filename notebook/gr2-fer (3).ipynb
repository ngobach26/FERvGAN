{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":356254,"sourceType":"datasetVersion","datasetId":155246},{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":6504606,"sourceType":"datasetVersion","datasetId":3758654},{"sourceId":10560736,"sourceType":"datasetVersion","datasetId":6143039}],"dockerImageVersionId":30445,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ’¾ EDA","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport os\nimport json\nimport pickle\nimport seaborn as sns\nimport scikitplot\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n\n# Ensure warnings are ignored\nwarnings.filterwarnings('ignore')\n\n# Print TensorFlow version\nprint(tf.__version__)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:22.757746Z","iopub.execute_input":"2025-01-22T12:05:22.758200Z","iopub.status.idle":"2025-01-22T12:05:30.672153Z","shell.execute_reply.started":"2025-01-22T12:05:22.758153Z","shell.execute_reply":"2025-01-22T12:05:30.671013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = \"/kaggle/input/fer2013/train\" # Directory containing the training data\ntest_dir = \"/kaggle/input/fer2013/test\"  # Directory containing the validation data\ngen_dir = \"/kaggle/input/generated-fer/fer2013-300/fer2013-300\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:30.674168Z","iopub.execute_input":"2025-01-22T12:05:30.674753Z","iopub.status.idle":"2025-01-22T12:05:30.679276Z","shell.execute_reply.started":"2025-01-22T12:05:30.674724Z","shell.execute_reply":"2025-01-22T12:05:30.678326Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define parameters\nnum_classes = 7  # Number of classes in your dataset, adjust as needed\nnum_images_per_class = 5  # Number of images to visualize per class\n\n# 1. Basic Information about Dataset\ndef dataset_info(directory):\n    class_names = os.listdir(directory)\n    num_samples = {class_name: len(os.listdir(os.path.join(directory, class_name))) for class_name in class_names}\n    \n    print(\"Classes and Sample Counts:\")\n    for class_name, count in num_samples.items():\n        print(f\"{class_name}: {count} images\")\n    return class_names, num_samples","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:30.680412Z","iopub.execute_input":"2025-01-22T12:05:30.680686Z","iopub.status.idle":"2025-01-22T12:05:30.709111Z","shell.execute_reply.started":"2025-01-22T12:05:30.680660Z","shell.execute_reply":"2025-01-22T12:05:30.708273Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. Class Distribution Plot\ndef plot_class_distribution(num_samples):\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=list(num_samples.keys()), y=list(num_samples.values()), palette=\"viridis\")\n    plt.title(\"Class Distribution\")\n    plt.xlabel(\"Class\")\n    plt.ylabel(\"Number of Samples\")\n    plt.xticks(rotation=45)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:30.710240Z","iopub.execute_input":"2025-01-22T12:05:30.711075Z","iopub.status.idle":"2025-01-22T12:05:30.720545Z","shell.execute_reply.started":"2025-01-22T12:05:30.711039Z","shell.execute_reply":"2025-01-22T12:05:30.719778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Visualize Sample Images from Each Class\ndef visualize_sample_images(directory, class_names, num_images_per_class=5):\n    plt.figure(figsize=(num_images_per_class * 2, len(class_names) * 2))\n    \n    for i, class_name in enumerate(class_names):\n        class_dir = os.path.join(directory, class_name)\n        images = os.listdir(class_dir)\n        selected_images = np.random.choice(images, num_images_per_class, replace=False)\n        \n        for j, img_name in enumerate(selected_images):\n            img_path = os.path.join(class_dir, img_name)\n            img = load_img(img_path, target_size=(48, 48))\n            \n            ax = plt.subplot(len(class_names), num_images_per_class, i * num_images_per_class + j + 1)\n            ax.imshow(img)\n            ax.axis(\"off\")\n            if j == 0:\n                ax.set_title(class_name, fontsize=10)\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:30.721698Z","iopub.execute_input":"2025-01-22T12:05:30.721993Z","iopub.status.idle":"2025-01-22T12:05:30.736999Z","shell.execute_reply.started":"2025-01-22T12:05:30.721967Z","shell.execute_reply":"2025-01-22T12:05:30.736053Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training data info and EDA\nprint(\"Training Data EDA:\")\ntrain_class_names, train_num_samples = dataset_info(train_dir)\nplot_class_distribution(train_num_samples)\nvisualize_sample_images(train_dir, train_class_names, num_images_per_class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:30.738007Z","iopub.execute_input":"2025-01-22T12:05:30.738269Z","iopub.status.idle":"2025-01-22T12:05:32.396640Z","shell.execute_reply.started":"2025-01-22T12:05:30.738238Z","shell.execute_reply":"2025-01-22T12:05:32.395702Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Testing data info and EDA (if you want to repeat for the test data)\nprint(\"\\nTesting Data EDA:\")\ntest_class_names, test_num_samples = dataset_info(test_dir)\nplot_class_distribution(test_num_samples)\nvisualize_sample_images(test_dir, test_class_names, num_images_per_class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:32.399050Z","iopub.execute_input":"2025-01-22T12:05:32.399342Z","iopub.status.idle":"2025-01-22T12:05:34.128296Z","shell.execute_reply.started":"2025-01-22T12:05:32.399315Z","shell.execute_reply":"2025-01-22T12:05:34.127313Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\Generated Data EDA:\")\ngen_class_names, gen_num_samples = dataset_info(gen_dir)\nplot_class_distribution(gen_num_samples)\nvisualize_sample_images(gen_dir, gen_class_names, num_images_per_class)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:34.129526Z","iopub.execute_input":"2025-01-22T12:05:34.129812Z","iopub.status.idle":"2025-01-22T12:05:35.671317Z","shell.execute_reply.started":"2025-01-22T12:05:34.129786Z","shell.execute_reply":"2025-01-22T12:05:35.670347Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Without any data augmentation\n","metadata":{}},{"cell_type":"markdown","source":"# Modeling ","metadata":{}},{"cell_type":"code","source":"img_size = 48 #original size of the image\nbatch_size = 16\nepochs = 60","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:35.672496Z","iopub.execute_input":"2025-01-22T12:05:35.672763Z","iopub.status.idle":"2025-01-22T12:05:35.676907Z","shell.execute_reply.started":"2025-01-22T12:05:35.672737Z","shell.execute_reply":"2025-01-22T12:05:35.676001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define ImageDataGenerators for non-augmented and augmented datasets\ntrain_datagen_no_aug = ImageDataGenerator(\n    rescale=1./255,\n)\n\nvalidation_datagen = ImageDataGenerator(\n    rescale=1./255,\n)\n\ntrain_datagen_aug = ImageDataGenerator(\n    rescale=1./255,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n)\n\ntrain_datagen_gan = ImageDataGenerator(\n    rescale=1./255,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n)\n\n\n# Create data generators for training and validation without augmentation\ntrain_generator_no_aug = train_datagen_no_aug.flow_from_directory(\n    directory=train_dir,\n    target_size=(img_size, img_size),\n    batch_size=batch_size,\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\",\n)\n\n# Create data generators for training and validation with augmentation\ntrain_generator_aug = train_datagen_aug.flow_from_directory(\n    directory=train_dir,\n    target_size=(img_size, img_size),\n    batch_size=batch_size,\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\"\n)\n\ntrain_generator_gan = train_datagen_gan.flow_from_directory(\n    directory=gen_dir,\n    target_size=(img_size, img_size),\n    batch_size=batch_size,\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\"\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    directory=test_dir,\n    target_size=(img_size, img_size),\n    batch_size=batch_size,\n    color_mode=\"grayscale\",\n    class_mode=\"categorical\",\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:05:35.678277Z","iopub.execute_input":"2025-01-22T12:05:35.679161Z","iopub.status.idle":"2025-01-22T12:06:22.491494Z","shell.execute_reply.started":"2025-01-22T12:05:35.679133Z","shell.execute_reply":"2025-01-22T12:06:22.490670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import clone_model\n\n# Define your model as a function to re-instantiate it fresh for each dataset\ndef create_model():\n    model = tf.keras.models.Sequential()\n    model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48,1)))\n    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, (5,5), padding='same', activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(512, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(512, (3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(BatchNormalization())\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten()) \n    model.add(Dense(256, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n\n    model.add(Dense(512, activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25))\n\n    model.add(Dense(7, activation='softmax'))\n    \n    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:06:22.492704Z","iopub.execute_input":"2025-01-22T12:06:22.493077Z","iopub.status.idle":"2025-01-22T12:06:22.509025Z","shell.execute_reply.started":"2025-01-22T12:06:22.493032Z","shell.execute_reply":"2025-01-22T12:06:22.508205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\ntf.keras.backend.clear_session()\n\n# Define datasets with augmentation options\ndatasets = [\n    (\"Non-Augmented\", train_generator_no_aug, validation_generator),\n    (\"Augmented\", train_generator_aug, validation_generator),\n    (\"GAN\", train_generator_gan, validation_generator)\n]\n\n# Create directories to store models and histories\nos.makedirs(\"models\", exist_ok=True)\nos.makedirs(\"histories\", exist_ok=True)\n\n# Store training histories\ntraining_histories = []\n\n# Function to compute F1 score and plot confusion matrix\ndef compute_f1_and_plot_heatmap(model, validation_generator, dataset_name):\n    # Get true labels and predictions\n    true_labels = validation_generator.classes\n    class_indices = list(validation_generator.class_indices.keys())\n    \n    # Predict on the validation data\n    predictions = model.predict(validation_generator, verbose=1)\n    predicted_classes = np.argmax(predictions, axis=1)\n\n    # Calculate F1 score\n    f1 = f1_score(true_labels, predicted_classes, average='weighted')\n    print(\"\\nClassification Report:\\n\")\n    print(classification_report(true_labels, predicted_classes, target_names=class_indices))\n    print(f\"\\nWeighted F1 Score: {f1}\\n\")\n    \n    # Plot confusion matrix as heatmap\n    cm = confusion_matrix(true_labels, predicted_classes)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_indices, yticklabels=class_indices)\n    plt.title(f\"Confusion Matrix for {dataset_name}\")\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    plt.show()\n    \n    return f1\n\n# Loop through datasets to train on each one\nfor dataset_name, train_generator, validation_generator in datasets:\n    print(f\"Training on {dataset_name} dataset...\")\n\n    # Create a fresh model instance\n    model = create_model()\n\n    # Define early stopping to prevent overfitting\n    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n    # Train the model on the current dataset\n    history = model.fit(\n        train_generator,\n        validation_data=validation_generator,\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=[early_stopping],\n        verbose=1\n    )\n\n    # Save the model\n    model.save(f\"models/{dataset_name}_model.h5\")\n    \n    # Save the training history\n    with open(f\"histories/{dataset_name}_history.json\", 'w') as f:\n        json.dump(history.history, f)\n\n    # Compute F1 score and plot confusion matrix\n    f1 = compute_f1_and_plot_heatmap(model, validation_generator, dataset_name)\n\n    # Append history and F1 score for comparison\n    training_histories.append((dataset_name, history.history, f1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:06:22.510300Z","iopub.execute_input":"2025-01-22T12:06:22.510552Z","iopub.status.idle":"2025-01-22T12:34:04.781398Z","shell.execute_reply.started":"2025-01-22T12:06:22.510528Z","shell.execute_reply":"2025-01-22T12:34:04.780392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display results for all datasets\nfor dataset_name, _, f1 in training_histories:\n    print(f\"{dataset_name} Dataset - Weighted F1 Score: {f1}\")\n\n# Visualize training histories\nfor dataset_name, history, _ in training_histories:\n    fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n    \n    # Training and validation accuracy\n    ax[0].plot(history['accuracy'], label='Train Accuracy')\n    ax[0].plot(history['val_accuracy'], label='Validation Accuracy')\n    ax[0].set_title(f'{dataset_name} - Training Accuracy vs Validation Accuracy')\n    ax[0].set_ylabel('Accuracy')\n    ax[0].set_xlabel('Epoch')\n    ax[0].legend(loc='upper left')\n\n    # Training and validation loss\n    ax[1].plot(history['loss'], label='Train Loss')\n    ax[1].plot(history['val_loss'], label='Validation Loss')\n    ax[1].set_title(f'{dataset_name} - Training Loss vs Validation Loss')\n    ax[1].set_ylabel('Loss')\n    ax[1].set_xlabel('Epoch')\n    ax[1].legend(loc='upper left')\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T12:34:04.782576Z","iopub.execute_input":"2025-01-22T12:34:04.782851Z","iopub.status.idle":"2025-01-22T12:34:05.406394Z","shell.execute_reply.started":"2025-01-22T12:34:04.782824Z","shell.execute_reply":"2025-01-22T12:34:05.405468Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GAN","metadata":{}}]}